---
layout: article
title: Extended trolley problem
date: '2015-10-28 19:56:25 -0700'
author: Matt Young
mt_id: 7138
blog_id: 2
post_id: 7138
basename: extended_trolle
---
I just ran across this article, [Should a self-driving car kill its passengers in a "greater good" scenario?](http://www.iflscience.com/technology/should-self-driving-car-be-programmed-kill-its-passengers-greater-good-scenario) Though the article does not say so, it is the [trolley problem](https://en.wikipedia.org/wiki/Trolley_problem), but with a twist: You are the driver of the trolley, and you have to ask whether _you_ ought to be sacrificed for the greater good.  That is, there are now three possibilities, not two: do nothing and kill five people; swerve and kill one; or (the added possibility) swerve and kill yourself. Any thoughts?
