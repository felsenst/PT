---
layout: article
title: The deniers of science Part 2
date: '2007-03-18 22:59:24 -0700'
author: PvM
mt_id: 2893
blog_id: 2
post_id: 2893
basename: the_deniers_of_1
---
In part 1, I showed how GilDodgen's concerns about computer models show how Intelligent Design is scientifically vacuous, but since evolution deniers often also tend to be global warming deniers (often for very similar reasons), it may be helpful and beneficial to explore in more depth the value of computer models in science.

Let's first explain how computer simulations of global warming take place and why we can indeed trust the results. We often hear arguments from global warming deniers which take shape as follows: 

> We all know that the weather is unpredictable beyond a certain time frame of 7-10 days so how can climate models be trusted?

This fallacious argument is based on a confusion of weather and climate. Climate is a statistical concept based on the outcome of many computer runs with slightly different models, conditions, weather is a local (and real) phenomenon  (I already pointed out these differences when discussing Bill Dembski's [flawed understandings](/archives/2007/02/bill-and-his-st.html) of these basic concepts.

>    **Definition of climate (Edward Lorenz)**:
> "Climate is what you expect, weather is what you get."
> 
> **Updated for the 21st century (Myles Allen):**
> "Climate is what you affect, weather is what gets you."

Climate modelers use what is commonly known as General Circulation Models (GCM) which differ from [weather prediction models](http://www-das.uwyo.edu/~geerts/cwx/notes/chap12/nwp_gcm.html) in several important aspects. 

So how do climate modelers approach modeling and predicting the climate? First of all, it is important to realize that general circulation models are based on  scientific principles of physics.

\[PvM: Updated for accuracy\]
In other words, models use first principles from physics to model the motion of water and air.

For instance the equations for the velocity components (u,v,w) follow from the [Navier Stokes](http://en.wikipedia.org/wiki/Navier-Stokes_equations) equations which are themselves based on 1) the conservation of mass (leading to the continuity equation) 2) the conservation of momentum 3) conservation of energy.
Finally, the equation of state relates the density to the temperature (and salinity). 

The [Navier Stokes equations](http://www.grc.nasa.gov/WWW/K-12/airplane/nseqs.html) can often be further simplified based on scaling arguments and can supporting rotating bodies (such as the earth) which add the [Coriolis force](http://scienceworld.wolfram.com/physics/Navier-StokesEquationsRotational.html).

Circulation models for oceans and circulation models for the atmosphere are coupled at their natural interface and boundary conditions model the exchange of heat (for instance solar), moisture (precipitation, evaporation) and momentum (wind stress) at this interface. Under certain circumstance the top of the ocean (boundary layer) can become well mixed and form what is called the 'mixed layer'.
\[update end\]

Of course, this does not mean that there are no problems with such models. For instance, since the grid size of these models can be quite large, processes of turbulence and other processes which happen at a smaller scale will need to be approximated. And then there are processes of cloud formation, precipitation, melting of sea or land ice which are non-trivial.

So once a model has been built, do modelers just initialize it, and then predict the future? If it were only that simple. First of all, the models are run with historical data to determine how well these models can capture the physics involved. In other words, the models are validated against known data. In addition, these models are often validated against other models which have earned their stripes.

So how is a climate 'predicted'? Climate modelers typically use a variety of models, a variety of initial conditions and a variety of scenarios to determine what the climate will look like in the near of far future. Since climate is a probabilistic concept, climate is predicted with likely ranges.

While it is indeed possible to make a model which will do anything one wants, it is much harder to 1) make a model based on actual physical principles reach a particular conclusion 2) have other models replicate these findings. In other words, like any science modeling includes verification and thus rejection.

This means that if global warming deniers are convinced that the models are somehow wrong, that all they need to do is present their own results. And here we find another similarity between global warming deniers and evolution deniers: they seldomly perform the hard work necessary to support their claims.

Let's look at evolutionary models and ask the simple question: What do these models show? Remember that evolution deniers claim that evolution cannot in principle generate the complexity found in nature because processes of chance and regularity are unable to generate complex specified information.
Such a claim can be simply shown erroneous by showing, as science has done, that simple processes of variation and selection, indeed can generate complex specified information. In other words, even if one were to accept the claim by evolution deniers such as GilDodgen that evolutionary models are without relevance because they can model almost anything (a fallacious assumption as I have shown), these models do show that one of the fundamental claims of ID is erroneous.

**References**:


* [History of General Circulation models](http://www.aip.org/history/climate/GCM.htm)
